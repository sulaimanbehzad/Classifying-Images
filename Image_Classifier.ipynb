{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classifiers.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/sulaimanbehzad/Classifying-Images/blob/main/Captions_Classifiers.ipynb",
      "authorship_tag": "ABX9TyNKv8pzXr/PbHpwQfb6Z96a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sulaimanbehzad/Classifying-Images/blob/main/Image_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXCGKES9z2uu"
      },
      "source": [
        "# Classifiers\r\n",
        "The purpose of this project is to train two classifiers:\r\n",
        "1. Captions classifier\r\n",
        "2. Image classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enfmzwTK6_aE"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "import imageio\r\n",
        "import cv2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quS7tRcgGr7x"
      },
      "source": [
        "## Part 2: Image Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAKptlEqGxda"
      },
      "source": [
        "Reading the images and format them into a dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS32CGUV7QZQ"
      },
      "source": [
        "# function for reading images into a pandas dataframe\r\n",
        "def read_data_into_df(filespath):\r\n",
        "  levels = 0\r\n",
        "  default_size = 256\r\n",
        "  for roots, dirnames, filenames in os.walk(filespath):\r\n",
        "    if levels == 0:\r\n",
        "      df = pd.DataFrame(columns=dirnames)\r\n",
        "    im_list = []\r\n",
        "    for fn in filenames:\r\n",
        "      im_full_path = os.path.join(roots, fn)\r\n",
        "      # print(txtfile_full_path)\r\n",
        "      # temp=pd.read_csv(txtfile_full_path,sep=\"\\\\n\", header=None, error_bad_lines=False)\r\n",
        "      # print('shape of temp: ', temp.shape)\r\n",
        "      # txt_list.append(temp.values)\r\n",
        "      # -------------------- another approach to read txt files\r\n",
        "      im = cv2.imread(im_full_path)[...,::-1] \r\n",
        "      im_resized = cv2.resize(im, (default_size, default_size))\r\n",
        "      im_list.append(im_resized)\r\n",
        "    root = os.path.split(roots) \r\n",
        "    root = root[1]\r\n",
        "    # print(root)\r\n",
        "    if levels != 0:\r\n",
        "      df[root] = im_list\r\n",
        "    levels+=1\r\n",
        "  return df\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "g7SlG4NBQIjx"
      },
      "source": [
        "path_train_sentences = r'/content/drive/MyDrive/dataset/train/images'   \r\n",
        "path_test_sentences =  r'/content/drive/MyDrive/dataset/test/images'   \r\n",
        "train = read_data_into_df(path_train_sentences)\r\n",
        "test = read_data_into_df(path_test_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHqn1AOA5oFI"
      },
      "source": [
        "### Dataframe inspection, evaluation and preprocessing\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCEEUJk2YbKh"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bU47h99KenE9"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMsQhMKy52w3"
      },
      "source": [
        "The dataframes don't have any null values so we are good to go on that aspect  \r\n",
        "What remains is to add tags to the captions of each type"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gezkhxEteout"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5M7d2IueqO7"
      },
      "source": [
        "test.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GuddkUOuf1nA"
      },
      "source": [
        "for i in train['chair']:\r\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "GDxQOZpWgbEk"
      },
      "source": [
        "def make_tabular_df(df):\r\n",
        "  tags = df.columns\r\n",
        "  df_transpose = df.transpose(copy=False)\r\n",
        "  output = pd.DataFrame(columns=['captions',  'tags'])\r\n",
        "  for index, col in df_transpose.iteritems():\r\n",
        "    new = []\r\n",
        "    for item in col:\r\n",
        "      new.append(item)\r\n",
        "    df=pd.DataFrame({\"captions\": new, \"tags\": tags})\r\n",
        "    output=output.append(df)\r\n",
        "  return output\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqjbYrsU1zq7"
      },
      "source": [
        "X_train = make_tabular_df(train)\r\n",
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjEp1lEZpunw"
      },
      "source": [
        "X_test = make_tabular_df(test)\r\n",
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "163mtZlT6zD7"
      },
      "source": [
        "We obtained the dataframes ready to go to next phase\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY1DWmbC_sjJ"
      },
      "source": [
        "plt.figure(figsize=(24,20))\r\n",
        "X_train.tags.value_counts().plot(kind='bar', color=['Blue', 'Red', 'Brown', 'Gray']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFLQNUtqLa2w"
      },
      "source": [
        "We can confirm visually that our dataset is balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Js66NL3IFWd"
      },
      "source": [
        "## Bag-Of-Words (BOW) with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7qgnRsBITSa"
      },
      "source": [
        "print(f\"train size: {len(X_train)}\")\r\n",
        "print(f\"test size: {len(X_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhjGieriNphD"
      },
      "source": [
        "max_words = 1500\r\n",
        "tokenizer = text.Tokenizer(num_words=max_words, char_level=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGElW3wFOiuG"
      },
      "source": [
        "tokenizer.fit_on_texts(X_train['captions']) \r\n",
        "x_train = tokenizer.texts_to_matrix(X_train['captions'])\r\n",
        "x_test = tokenizer.texts_to_matrix(X_test['captions'])\r\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIes7LopO8pi"
      },
      "source": [
        "x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQkviOeSPFaI"
      },
      "source": [
        "print(f'shape of new x_train is: {x_train.shape}')\r\n",
        "print(f'shape of new x_test is: {x_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgcCHVjTPtho"
      },
      "source": [
        "in both encoder and tokenizer we only fit on train for consistency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsBYBUQ-Pc-v"
      },
      "source": [
        "le = LabelEncoder()\r\n",
        "le.fit(X_train['tags'])\r\n",
        "y_train = le.transform(X_train['tags'])\r\n",
        "y_test = le.transform(X_test['tags'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m64FspuFP-0n"
      },
      "source": [
        "print(f'shape of new y_train is: {y_train.shape}')\r\n",
        "print(f'shape of new y_test is: {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YR-w9hPQOfP"
      },
      "source": [
        "Convert the enoded y_train and y_test to one-hot representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVb477nxQiC9"
      },
      "source": [
        "num_tags = np.max(y_train) + 1\r\n",
        "y_train = utils.to_categorical(y_train, num_tags)\r\n",
        "y_test = utils.to_categorical(y_test, num_tags)\r\n",
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hwc0hlFbQtIl"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udRHS6PtQzdO"
      },
      "source": [
        "print(f'shape of new x_train is: {x_train.shape}')\r\n",
        "print(f'shape of new x_test is: {x_test.shape}')\r\n",
        "print(f'shape of new y_train is: {y_train.shape}')\r\n",
        "print(f'shape of new y_test is: {y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwQxR_XSQ_uc"
      },
      "source": [
        "Let's set our hyperparameters  \r\n",
        "we will adjust these later to, if possible, reach higher accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r15CKSBZRYga"
      },
      "source": [
        "batch_size = 16\r\n",
        "epochs = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mr-nzu4Ror3"
      },
      "source": [
        "Buliding the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxUmFpr9Rdc-"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(512, input_shape=(max_words,)))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(num_tags))\r\n",
        "model.add(Activation('softmax'))\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer='adam',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw404ArDRnea"
      },
      "source": [
        "we have the model, train and test data prepared  \r\n",
        "so let's train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlyiEGI8SUfF"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\r\n",
        "                    verbose=1, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG3xW1ODS-Gj"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\r\n",
        "print(f'Test score:{score[0]}')\r\n",
        "print(f'Test accuracy:{score[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMTOmF5DT2bE"
      },
      "source": [
        "txt_lbls = le.classes_ \r\n",
        "\r\n",
        "for i in range(10):\r\n",
        "    prediction = model.predict(np.array([x_test[i]]))\r\n",
        "    predicted_label = txt_lbls[np.argmax(prediction)]\r\n",
        "    print(X_test['captions'].iloc[i][:50], \"...\")\r\n",
        "    print('Actual label:' + X_test['tags'].iloc[i])\r\n",
        "    print(\"Predicted label: \" + predicted_label + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmTaddudU3a1"
      },
      "source": [
        "# This utility function is from the sklearn docs: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\r\n",
        "import itertools\r\n",
        "def plot_confusion_matrix(cm, classes,\r\n",
        "                          title='Confusion matrix',\r\n",
        "                          cmap=plt.cm.Blues):\r\n",
        "    \"\"\"\r\n",
        "    This function prints and plots the confusion matrix.\r\n",
        "    Normalization can be applied by setting `normalize=True`.\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\r\n",
        "\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title, fontsize=30)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, rotation=45, fontsize=22)\r\n",
        "    plt.yticks(tick_marks, classes, fontsize=22)\r\n",
        "\r\n",
        "    fmt = '.2f'\r\n",
        "    thresh = cm.max() / 2.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\r\n",
        "                 horizontalalignment=\"center\",\r\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.ylabel('True label', fontsize=25)\r\n",
        "    plt.xlabel('Predicted label', fontsize=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPGnriQ5VPCf"
      },
      "source": [
        "y_sm = model.predict(x_test)\r\n",
        "\r\n",
        "y_test_1d = []\r\n",
        "y_pred_1d = []\r\n",
        "\r\n",
        "for i in range(len(y_test)):\r\n",
        "    probs = y_test[i]\r\n",
        "    index_arr = np.nonzero(probs)\r\n",
        "    one_hot_index = index_arr[0].item(0)\r\n",
        "    y_test_1d.append(one_hot_index)\r\n",
        "\r\n",
        "for i in range(0, len(y_sm)):\r\n",
        "    probs = y_sm[i]\r\n",
        "    predicted_index = np.argmax(probs)\r\n",
        "    y_pred_1d.append(predicted_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-1C_k8bVeB_"
      },
      "source": [
        "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\r\n",
        "plt.figure(figsize=(24,20))\r\n",
        "plot_confusion_matrix(cnf_matrix, classes=txt_lbls, title=\"Confusion matrix\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
